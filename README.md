# Multiple-Regression

Multiple regression is a statistical technique that aims to predict a variable of interest from several other variables. The variable that's predicted is known as the criterion. The variables that predict the criterion are known as predictors.

In general, the multiple regression equation of Y on X1, X2, …, Xk is given by:

Y = b0 + b1 X1 + b2 X2 + …………………… + bk Xk

y = dependent variable

x = expanatory variables

b0 = y-intercept (constant term)

bk = slope coefficients for each explanatory variable

ϵ = the model’s error term (also known as the residuals)




The multiple regression model is based on the following assumptions:

 #There is a linear relationship between the dependent variables and the independent variables.
 #The independent variables are not too highly correlated with each other.
 #yi observations are selected independently and randomly from the population.
 #Residuals should be normally distributed with a mean of 0 and variance σ.
 
 The coefficient of determination (R-squared) is a statistical metric that is used to measure how much of the variation in outcome can be explained by the variation in the independent variables. R2 always increases as more predictors are added to the MLR model even though the predictors may not be related to the outcome variable.
 
When interpreting the results of a multiple regression, beta coefficients are valid while holding all other variables constant ("all else equal"). The output from a multiple regression can be displayed horizontally as an equation, or vertically in table form.
 
Multiple linear regression (MLR), also known simply as multiple regression, is a statistical technique that uses several explanatory variables to predict the outcome of a response variable.

Multiple regression is an extension of linear (OLS) regression that uses just one explanatory variable.
MLR is used extensively in econometrics and financial inference.

